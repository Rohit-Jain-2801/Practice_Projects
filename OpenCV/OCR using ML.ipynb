{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten-Digit Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV comes with an image digits.png which has 5000 handwritten digits (500 for each digit). Each digit is a 20x20 image. So our first step is to split this image into 5000 different digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation, Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of our cells array: (50, 100, 20, 20)\n",
      "Accuracy = 93.47%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Let's take a look at our digits dataset\n",
    "image = cv2.imread('images/digits.png')\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "small = cv2.pyrDown(image)\n",
    "cv2.imshow('Digits Image', small)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Split the image to 5000 cells, each 20x20 size\n",
    "# This gives us a 4-dim array: 50 x 100 x 20 x 20\n",
    "cells = [np.hsplit(row, 100) for row in np.vsplit(gray, 50)]\n",
    "\n",
    "# Convert the List data type to Numpy Array of shape (50, 100, 20, 20)\n",
    "x = np.array(cells)\n",
    "print(\"The shape of our cells array: \" + str(x.shape))\n",
    "\n",
    "# Split the full data set into two segments\n",
    "# One will be used for Training the model, the other as a test data set\n",
    "train = x[:, :70].reshape(-1, 400).astype(np.float32) # Size = (3500, 400)\n",
    "test = x[:, 70:100].reshape(-1, 400).astype(np.float32) # Size = (1500, 400)\n",
    "\n",
    "# Create labels for train and test data\n",
    "k = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]    # np.arange(10)\n",
    "train_labels = np.repeat(k, 350)[:, np.newaxis]\n",
    "test_labels = np.repeat(k, 150)[:, np.newaxis]\n",
    "\n",
    "# Initiate kNN, train the data, then test it with test data for k=3\n",
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(train, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "ret, result, neighbors, distance = knn.findNearest(test, k=3)\n",
    "\n",
    "# Now we check the accuracy of classification\n",
    "# For that, compare the result with test_labels and check which are wrong\n",
    "matches = result == test_labels\n",
    "correct = np.count_nonzero(matches)\n",
    "accuracy = correct * (100.0 / result.size)\n",
    "print(\"Accuracy = %.2f\" % accuracy + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining some functions that will be used to prepare an input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Define our functions\n",
    "\n",
    "def x_cord_contour(contour):\n",
    "    # This function take a contour from findContours\n",
    "    # it then outputs the x centroid coordinates\n",
    "    if cv2.contourArea(contour) > 10:\n",
    "        M = cv2.moments(contour)\n",
    "        return (int(M['m10']/M['m00']))\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def makeSquare(not_square):\n",
    "    # This function takes an image and makes the dimenions square\n",
    "    # It adds black pixels as the padding where needed\n",
    "    BLACK = [0, 0, 0]\n",
    "    img_dim = not_square.shape\n",
    "    height = img_dim[0]\n",
    "    width = img_dim[1]\n",
    "    #print(\"Height = \", height, \"Width = \", width)\n",
    "    if (height == width):\n",
    "        square = not_square\n",
    "        return square\n",
    "    else:\n",
    "        doublesize = cv2.resize(not_square, (2*width, 2*height), interpolation=cv2.INTER_CUBIC)\n",
    "        height = height * 2\n",
    "        width = width * 2\n",
    "        #print(\"New Height = \", height, \"New Width = \", width)\n",
    "        if (height > width):\n",
    "            pad = int((height - width)/2)\n",
    "            #print(\"Padding = \", pad)\n",
    "            doublesize_square = cv2.copyMakeBorder(doublesize, 0, 0, pad, pad, cv2.BORDER_CONSTANT, value=BLACK)\n",
    "        else:\n",
    "            pad = int((width - height)/2)\n",
    "            #print(\"Padding = \", pad)\n",
    "            doublesize_square = cv2.copyMakeBorder(doublesize, pad, pad, 0, 0, cv2.BORDER_CONSTANT, value=BLACK)\n",
    "    doublesize_square_dim = doublesize_square.shape\n",
    "    #print(\"Sq Height = \", doublesize_square_dim[0], \"Sq Width = \", doublesize_square_dim[1])\n",
    "    return doublesize_square\n",
    "\n",
    "\n",
    "def resize_to_pixel(dimensions, image):\n",
    "    # This function then re-sizes an image to the specificied dimenions\n",
    "    buffer_pix = 4\n",
    "    dimensions  = dimensions - buffer_pix\n",
    "    squared = image\n",
    "    r = float(dimensions) / squared.shape[1]\n",
    "    dim = (dimensions, int(squared.shape[0] * r))\n",
    "    resized = cv2.resize(image, dim, interpolation=cv2.INTER_AREA)\n",
    "    img_dim2 = resized.shape\n",
    "    height_r = img_dim2[0]\n",
    "    width_r = img_dim2[1]\n",
    "    BLACK = [0, 0, 0]\n",
    "    if (height_r > width_r):\n",
    "        resized = cv2.copyMakeBorder(resized, 0, 0, 0, 1, cv2.BORDER_CONSTANT, value=BLACK)\n",
    "    if (height_r < width_r):\n",
    "        resized = cv2.copyMakeBorder(resized, 1, 0, 0, 0, cv2.BORDER_CONSTANT, value=BLACK)\n",
    "    p = 2\n",
    "    ReSizedImg = cv2.copyMakeBorder(resized, p, p, p, p, cv2.BORDER_CONSTANT, value=BLACK)\n",
    "    img_dim = ReSizedImg.shape\n",
    "    height = img_dim[0]\n",
    "    width = img_dim[1]\n",
    "    #print(\"Padded Height = \", height, \"Width = \", width)\n",
    "    return ReSizedImg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a new image, preprocessing it & classifying the digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number is: 13540\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('images/numbers.jpg')\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"image\", image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Blur image then find edges using Canny \n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "edged = cv2.Canny(blurred, 30, 150)\n",
    "\n",
    "# Fint Contours\n",
    "contours, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#Sort out contours left to right by using their x cordinates\n",
    "contours = sorted(contours, key=x_cord_contour, reverse=False)\n",
    "\n",
    "# Create empty array to store entire number\n",
    "full_number = []\n",
    "\n",
    "# loop over the contours\n",
    "for c in contours:\n",
    "    # compute the bounding box for the rectangle\n",
    "    (x, y, w, h) = cv2.boundingRect(c)    \n",
    "    \n",
    "    #cv2.drawContours(image, contours, -1, (0,255,0), 3)\n",
    "    #cv2.imshow(\"Contours\", image)\n",
    "\n",
    "    if w >= 5 and h >= 25:\n",
    "        roi = blurred[y:y + h, x:x + w]\n",
    "        ret, roi = cv2.threshold(roi, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "#         cv2.imshow('ROI', roi)\n",
    "        squared = makeSquare(roi)\n",
    "#         cv2.imshow('Squared', squared)\n",
    "        final = resize_to_pixel(20, squared)\n",
    "#         cv2.imshow('Final', final)\n",
    "        final_array = final.reshape((1, 400))\n",
    "        final_array = final_array.astype(np.float32)\n",
    "        ret, result, neighbours, dist = knn.findNearest(final_array, k=1)\n",
    "        number = str(int(float(result[0])))\n",
    "        full_number.append(number)\n",
    "        # draw a rectangle around the digit, the show what the digit was classified as\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "        cv2.putText(image, number, (x , y + 155),\n",
    "            cv2.FONT_HERSHEY_COMPLEX, 2, (255, 0, 0), 2)\n",
    "        cv2.imshow(\"image\", image)\n",
    "        cv2.waitKey(0) \n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "print (\"The number is: \" + ''.join(full_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the data\n",
    "# np.savez('knn_data.npz',train=train, train_labels=train_labels)\n",
    "# # Now load the data\n",
    "# with np.load('knn_data.npz') as data:\n",
    "#     print( data.files )\n",
    "#     train = data['train']\n",
    "#     train_labels = data['train_labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alphabet Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will do the same for English alphabets, but there is a slight change in data and feature set. Here, instead of images, OpenCV comes with a data file, letter-recognition.data. If you open it, you will see 20000 lines which may, on first sight, look like garbage. Actually, in each row, first column is an alphabet which is our label. Next 16 numbers following it are its different features. These features are obtained from UCI Machine Learning Repository. You can find the details of these features in this page.\n",
    "\n",
    "There are 20000 samples available, so we take first 10000 data as training samples and remaining 10000 as test samples. We should change the alphabets to ascii characters because we can't work with alphabets directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 93.06%\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# Load the data, converters convert the letter to a number\n",
    "data= np.loadtxt('letter-recognition.data', dtype='float32', delimiter=',', converters={0: lambda ch: ord(ch)-ord('A')})\n",
    "\n",
    "# split the data to two, 10000 each for train and test\n",
    "train, test = np.vsplit(data, 2)\n",
    "\n",
    "# split trainData and testData to features and responses\n",
    "responses, trainData = np.hsplit(train, [1])\n",
    "labels, testData = np.hsplit(test, [1])\n",
    "\n",
    "# Initiate the kNN, classify, measure accuracy.\n",
    "knn = cv.ml.KNearest_create()\n",
    "knn.train(trainData, cv.ml.ROW_SAMPLE, responses)\n",
    "ret, result, neighbours, dist = knn.findNearest(testData, k=5)\n",
    "correct = np.count_nonzero(result == labels)\n",
    "accuracy = correct*100.0/10000\n",
    "print(\"Accuracy = %.2f\" % accuracy + \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
