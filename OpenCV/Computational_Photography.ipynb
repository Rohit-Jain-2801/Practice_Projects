{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are 4 variations of Non-Local Means Denoising:**\n",
    "\n",
    "- cv2.fastNlMeansDenoising() - works with a single grayscale images\n",
    "- cv2.fastNlMeansDenoisingColored() - works with a color image.\n",
    "- cv2.fastNlMeansDenoisingMulti() - works with image sequence captured in short period of time (grayscale images)\n",
    "- cv2.fastNlMeansDenoisingColoredMulti() - same as above, but for color images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('images/elephant.jpg')\n",
    "\n",
    "# cv2.fastNlMeansDenoisingColored(input, None, h, hForColorComponents, templateWindowSize, searchWindowSize)\n",
    "# None are - the filter strength 'h' (5-12 is a good range)\n",
    "# Next is hForColorComponents, set as same value as h again\n",
    "# templateWindowSize (odd numbers only) rec. 7\n",
    "# searchWindowSize (odd numbers only) rec. 21\n",
    "\n",
    "dst = cv2.fastNlMeansDenoisingColored(image, None, 11, 6, 7, 21)\n",
    "\n",
    "cv2.imshow('Fast Means Denoising', dst)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Inpainting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inpainting is the process of reconstructing lost or deteriorated parts of images and videos. It is an advanced form of interpolation that can be used to replace lost or corrupted parts of the image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load our damaged photo\n",
    "image = cv2.imread('images/abraham.jpg')\n",
    "cv2.imshow('Original Damaged Photo', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Load the photo where we've marked the damaged areas\n",
    "marked_damages = cv2.imread('images/mask.jpg', 0)\n",
    "cv2.imshow('Marked Damages', marked_damages)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Let's make a mask out of our marked image be changing all colors \n",
    "# that are not white, to black\n",
    "ret, thresh1 = cv2.threshold(marked_damages, 254, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow('Threshold Binary', thresh1)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Let's dilate (make thicker) our the marks w made\n",
    "# since thresholding has narrowed it slightly\n",
    "kernel = np.ones((7, 7), np.uint8)\n",
    "mask = cv2.dilate(thresh1, kernel, iterations=1)\n",
    "cv2.imshow('Dilated Mask', mask)\n",
    "cv2.imwrite(\"images/abraham_mask.png\", mask)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "restored = cv2.inpaint(image, mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA)\n",
    "# Radius of a circular neighborhood of each point inpainted that is considered by the algorithm,\n",
    "# Smaller values look less blurred, while larger values look more pixelated or blurred.\n",
    "\n",
    "cv2.imshow('Restored', restored)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Dynamic Range (HDR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High-dynamic-range imaging (HDRI or HDR) is a technique used in imaging and photography to reproduce a greater dynamic range of luminosity than is possible with standard digital imaging or photographic techniques. While the human eye can adjust to a wide range of light conditions, most imaging devices use 8-bits per channel, so we are limited to only 256 levels. When we take photographs of a real world scene, bright regions may be overexposed, while the dark ones may be underexposed, so we canâ€™t capture all details using a single exposure. HDR imaging works with images that use more than 8 bits per channel (usually 32-bit float values), allowing much wider dynamic range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def loadExposureSeq(path):\n",
    "    images = []\n",
    "    times = []\n",
    "    with open(os.path.join(path, 'list.txt')) as f:\n",
    "        content = f.readlines()\n",
    "    for line in content:\n",
    "        tokens = line.split()\n",
    "        images.append(cv2.imread(os.path.join(path, tokens[0])))\n",
    "        times.append(1 / float(tokens[1]))\n",
    "    return images, np.asarray(times, dtype=np.float32)\n",
    "    \n",
    "# Load images and exposure times\n",
    "images, times = loadExposureSeq('images/exposures/')\n",
    "\n",
    "# Estimate camera response\n",
    "calibrate = cv2.createCalibrateDebevec()\n",
    "response = calibrate.process(images, times)\n",
    "\n",
    "# Make HDR image\n",
    "merge_debevec = cv2.createMergeDebevec()\n",
    "hdr = merge_debevec.process(images, times, response)\n",
    "\n",
    "# Tonemap HDR image\n",
    "tonemap = cv2.createTonemap(2.2)    # Other ToneMap functions available\n",
    "ldr = tonemap.process(hdr)\n",
    "\n",
    "# Perform exposure fusion\n",
    "merge_mertens = cv2.createMergeMertens()\n",
    "fusion = merge_mertens.process(images)\n",
    "\n",
    "# Convert to 8-bit\n",
    "fusion_8bit = np.clip(fusion*255, 0, 255).astype('uint8')\n",
    "ldr_8bit = np.clip(ldr*255, 0, 255).astype('uint8')\n",
    "hdr_8bit = np.clip(hdr*255, 0, 255).astype('uint8')\n",
    "\n",
    "# Displaying results\n",
    "cv2.imshow('Fusion', fusion_8bit)\n",
    "cv2.imshow('LDR', ldr_8bit)\n",
    "cv2.imshow('HDR', hdr_8bit)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
