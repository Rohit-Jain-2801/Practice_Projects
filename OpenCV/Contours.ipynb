{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contour is an outline representing or bounding the shape.\n",
    "\n",
    "# For better accuracy, use binary images. So before finding contours, apply threshold or canny edge detection.\n",
    "# In OpenCV, finding contours is like finding white object from black background.\n",
    "#     So remember, object to be found should be white and background should be black.\n",
    "\n",
    "# There are three arguments in cv2.findContours() function,\n",
    "#     first one is source image, second is contour retrieval mode, third is contour approximation method.\n",
    "\n",
    "# Contour Retrieval Mode refers to hierarchy type\n",
    "# cv2.RETR_LIST => Retrieves all contours\n",
    "# cv2.RETR_EXTERNAL => Retrieves external or outer contours only\n",
    "# cv2.RETR_COMP => Retrieves all in a 2-level hierarchy\n",
    "# cv2.RETR_TREE => Retrieves all in full hierarchy\n",
    "\n",
    "# Contour Approximation Method specifies the number of co-ordinates/boundary points.\n",
    "# cv2.CHAIN_APPROX_NONE => stores all the boundary points. But we don't necessarily need all bounding points.\n",
    "#     If the points form a straight line, we only need the start and ending points of that line.\n",
    "# cv2.CHAIN_APPROX_SIMPLE => instead only provides these start and end points of bounding contours,\n",
    "#     thus resulting in much more efficent storage of contour information.\n",
    "\n",
    "# Each individual 'contour' is a Numpy array of (x,y) coordinates of boundary points of the object.\n",
    "# While, 'hierarchy' describes the child-parent relationships between contours (i.e. contours within contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 3\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Let's load a simple image with 3 black squares\n",
    "image = cv2.imread('images/shapes_donut.jpg')\n",
    "cv2.imshow('Input Image', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "blank_image = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "\n",
    "# Grayscale\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find Canny edges\n",
    "edged = cv2.Canny(gray, 30, 200)\n",
    "cv2.imshow('Canny Edges', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Finding Contours\n",
    "# Use a copy of your image e.g. edged.copy(), since findContours alters the image\n",
    "contours, hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) # will exclude internal rectangle\n",
    "# contours, hierarchy = cv2.findContours(edged, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE) # will include internal rectangle\n",
    "cv2.imshow('Canny Edges After Contouring', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print(\"Number of Contours found = \" + str(len(contours)))\n",
    "\n",
    "# Draw all contours\n",
    "# Use '-1' as the 3rd parameter to draw all\n",
    "cv2.drawContours(blank_image, contours, -1, (0,255,0), 3)\n",
    "cv2.imshow('Contours over blank image', blank_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.drawContours(image, contours, -1, (0,255,0), 3)\n",
    "cv2.imshow('Contours', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1 -1 -1 -1]\n",
      "  [ 2  0 -1 -1]\n",
      "  [-1  1 -1 -1]]]\n"
     ]
    }
   ],
   "source": [
    "# Hierarchy is stored in the following format: [Next, Previous, First Child, Parent]\n",
    "print(hierarchy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting Contours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 4\n",
      "Contor Areas before sorting [20587.5, 22905.0, 66581.5, 90222.0]\n",
      "Contor Areas after sorting [90222.0, 66581.5, 22905.0, 20587.5]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function we'll use to display contour area\n",
    "def get_contour_areas(contours):\n",
    "    # returns the areas of all contours as list\n",
    "    all_areas = []\n",
    "    for cnt in contours:\n",
    "        # Contour area is given by the function cv2.contourArea() or from moments, M[‘m00’].\n",
    "        area = cv2.contourArea(cnt)\n",
    "        all_areas.append(area)\n",
    "    return all_areas\n",
    "\n",
    "# Load our image\n",
    "image = cv2.imread('images/bunchofshapes.jpg')\n",
    "\n",
    "# Grayscale\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find Canny edges\n",
    "edged = cv2.Canny(gray, 30, 200)\n",
    "cv2.imshow('Canny Edges', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Finding Contours\n",
    "# Use a copy of your image e.g. edged.copy(), since findContours alters the image\n",
    "contours, hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "cv2.imshow('Canny Edges After Contouring', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print(\"Number of Contours found = \" + str(len(contours)))\n",
    "\n",
    "# Let's print the areas of the contours before sorting\n",
    "print(\"Contor Areas before sorting\", get_contour_areas(contours))\n",
    "\n",
    "# Sort contours large to small\n",
    "sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "# sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)[:3]\n",
    "\n",
    "print(\"Contor Areas after sorting\", get_contour_areas(sorted_contours))\n",
    "\n",
    "# Iterate over our contours and draw one at a time\n",
    "for c in sorted_contours:\n",
    "    cv2.drawContours(image, [c], -1, (255,0,0), 3)\n",
    "    cv2.imshow('Contours by area', image)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Functions we'll use for sorting by position\n",
    "def x_cord_contour(contours):\n",
    "    #Returns the X cordinate for the contour centroid\n",
    "    if cv2.contourArea(contours) > 10:\n",
    "        M = cv2.moments(contours)\n",
    "        return (int(M['m10']/M['m00']))\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# Load our image\n",
    "image = cv2.imread('images/bunchofshapes.jpg')\n",
    "\n",
    "# Grayscale\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find Canny edges\n",
    "edged = cv2.Canny(gray, 30, 200)\n",
    "cv2.imshow('Canny Edges', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Finding Contours\n",
    "# Use a copy of your image e.g. edged.copy(), since findContours alters the image\n",
    "contours, hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "cv2.imshow('Canny Edges After Contouring', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print(\"Number of Contours found = \" + str(len(contours)))\n",
    "\n",
    "# Computer Center of Mass or centroids and draw them on our image\n",
    "for c in contours:\n",
    "    # Places a red circle on the centers of contours\n",
    "    M = cv2.moments(c)\n",
    "    # Centroid are given by following relations\n",
    "    cx = int(M['m10'] / M['m00'])\n",
    "    cy = int(M['m01'] / M['m00'])\n",
    "    # Draw the countour number on the image\n",
    "    cv2.circle(image, (cx,cy), 10, (0, 0, 255), -1)\n",
    " \n",
    "cv2.imshow(\"Contour Centers \", image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Sort by left to right using our x_cord_contour function\n",
    "contours_left_to_right = sorted(contours, key=x_cord_contour, reverse=False)\n",
    "\n",
    "# Labeling Contours left to right\n",
    "for (i,c) in enumerate(contours_left_to_right):\n",
    "    cv2.drawContours(image, [c], -1, (0, 0, 255), 3)  \n",
    "    M = cv2.moments(c)\n",
    "    cx = int(M['m10'] / M['m00'])\n",
    "    cy = int(M['m01'] / M['m00'])\n",
    "    cv2.putText(image, str(i+1), (cx-10, cy-15), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow('Left to Right Contour', image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "#     (x, y, w, h) = cv2.boundingRect(c)  \n",
    "#     # Let's now crop each contour and save these images\n",
    "#     cropped_contour = image[y:y + h, x:x + w]\n",
    "#     image_name = \"output_shape_number_\" + str(i+1) + \".jpg\"\n",
    "#     print(image_name)\n",
    "#     cv2.imwrite(image_name, cropped_contour)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Perimeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perimeter = cv2.arcLength(cnt, True)    # cnt represents individual contour & True specifies closed figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contour Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is an implementation of Douglas-Peucker algorithm.\n",
    "# cv2.approxPolyDP(contour, Approximation Accuracy, Closed)\n",
    "\n",
    "# contour => individual contour we wish to approximate\n",
    "# Approximation Accuracy => Small values give precise approximations, large values give more generic approximation.\n",
    "#     A good rule of thumb is less than 5% of the contour perimeter\n",
    "# Closed => a boolean value that states whether the approximate contour should be open or closed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load image and keep a copy\n",
    "image = cv2.imread('images/house.jpg')\n",
    "orig_image = image.copy()\n",
    "cv2.imshow('Original Image', orig_image)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "# Grayscale and binarize\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Find contours \n",
    "contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "# Iterate through each contour and compute the bounding rectangle\n",
    "for c in contours:\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    cv2.rectangle(orig_image, (x, y), (x+w, y+h), (0, 0, 255), 2)    \n",
    "    cv2.imshow('Bounding Rectangle', orig_image)\n",
    "cv2.waitKey(0) \n",
    "    \n",
    "# Iterate through each contour and compute the approx contour\n",
    "for c in contours:\n",
    "    # Calculate accuracy as a percent of the contour perimeter\n",
    "    accuracy = 0.03 * cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, accuracy, True)\n",
    "    cv2.drawContours(image, [approx], 0, (0, 255, 0), 2)\n",
    "    cv2.imshow('Approx Poly DP', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convex Hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convex Hull will look similar to contour approximation, but it is not (Both may provide same results in some cases).\n",
    "# Here, cv2.convexHull() function checks a curve for convexity defects and corrects it.\n",
    "# Generally speaking, convex curves are the curves which are always bulged out, or at-least flat.\n",
    "# And if it is bulged inside, it is called convexity defects.\n",
    "\n",
    "# cv2.convexHull(points, hull, clockwise, returnPoints)\n",
    "# points => individual contours we pass into.\n",
    "# hull => is the output, normally we avoid it.\n",
    "# clockwise => Orientation flag. If it is True, the output convex hull is oriented clockwise; otherwise counter-clockwise.\n",
    "# returnPoints => If True, it returns the coordinates of the hull points.\n",
    "#                 If False, it returns the indices of contour points corresponding to the hull points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('images/hand.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "# Threshold the image\n",
    "ret, thresh = cv2.threshold(gray, 176, 255, 0)\n",
    "\n",
    "# Find contours \n",
    "contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "# Sort Contors by area and then remove the largest frame contour\n",
    "n = len(contours) - 1\n",
    "contours = sorted(contours, key=cv2.contourArea, reverse=False)[:n]\n",
    "\n",
    "# Iterate through contours and draw the convex hull\n",
    "for c in contours:\n",
    "    hull = cv2.convexHull(c)\n",
    "    cv2.drawContours(image, [hull], 0, (0, 255, 0), 2)\n",
    "    cv2.imshow('Convex Hull', image)\n",
    "\n",
    "cv2.waitKey(0)    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 3\n",
      "There should be at least 5 points to fit the ellipse in function\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load our image\n",
    "image = cv2.imread('images/thunder.jpg')\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Grayscale\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "ret,thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow('Threshold', thresh)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Find Canny edges\n",
    "edged = cv2.Canny(thresh, 30, 200)\n",
    "cv2.imshow('Canny Edges', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Finding Contours\n",
    "# Use a copy of your image e.g. edged.copy(), since findContours alters the image\n",
    "contours, hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "cv2.imshow('Canny Edges After Contouring', edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print(\"Number of Contours found = \" + str(len(contours)))\n",
    "\n",
    "# Straight Bounding Rectangle\n",
    "img1 = image.copy()\n",
    "for cnt in contours:\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    img1 = cv2.rectangle(img1, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "cv2.imshow('Straight Bounding Rectangle', img1)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Rotated Rectangle\n",
    "img2 = image.copy()\n",
    "for cnt in contours:\n",
    "    rect = cv2.minAreaRect(cnt)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "    img2 = cv2.drawContours(img2, [box], 0, (0, 0, 255), 2)\n",
    "cv2.imshow('Rotated Rectangle', img2)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Minimum Enclosing Circle\n",
    "img3 = image.copy()\n",
    "for cnt in contours:\n",
    "    (x, y), radius = cv2.minEnclosingCircle(cnt)\n",
    "    center = (int(x), int(y))\n",
    "    radius = int(radius)\n",
    "    img3 = cv2.circle(img3, center, radius, (0, 255, 0), 2)\n",
    "cv2.imshow('Minimum Enclosing Circle', img3)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Fitting an Ellipse\n",
    "if(len(contours)>4):\n",
    "    img4 = image.copy()\n",
    "    for cnt in contours:\n",
    "        ellipse = cv2.fitEllipse(cnt)\n",
    "        img4 = cv2.ellipse(img4, ellipse, (0, 255, 0), 2)\n",
    "    cv2.imshow('Fitting an Ellipse', img4)\n",
    "    cv2.waitKey(0)\n",
    "else:\n",
    "    print(\"There should be at least 5 points to fit the ellipse in function\")\n",
    "    \n",
    "# Fitting a Line\n",
    "img5 = image.copy()\n",
    "cnt = contours[2]\n",
    "rows, cols = img5.shape[:2]\n",
    "[vx, vy, x, y] = cv2.fitLine(cnt, cv2.DIST_L2, 0, 0.01, 0.01)\n",
    "lefty = int((-x*vy/vx) + y)\n",
    "righty = int(((cols-x)*vy/vx)+y)\n",
    "img5 = cv2.line(img5, (cols-1, righty), (0, lefty), (0, 255, 0), 2)\n",
    "cv2.imshow('Fitting an Line', img5)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Contours found = 4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load our image\n",
    "image = cv2.imread('images/bunchofshapes.jpg')\n",
    "\n",
    "# Grayscale\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Find Canny edges\n",
    "edged = cv2.Canny(gray, 30, 200)\n",
    "\n",
    "# Finding Contours\n",
    "# Use a copy of your image e.g. edged.copy(), since findContours alters the image\n",
    "contours, hierarchy = cv2.findContours(edged, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "print(\"Number of Contours found = \" + str(len(contours)))\n",
    "\n",
    "for cnt in contours:\n",
    "    leftmost = tuple(cnt[cnt[:,:,0].argmin()][0])\n",
    "    rightmost = tuple(cnt[cnt[:,:,0].argmax()][0])\n",
    "    topmost = tuple(cnt[cnt[:,:,1].argmin()][0])\n",
    "    bottommost = tuple(cnt[cnt[:,:,1].argmax()][0])\n",
    "    \n",
    "    cv2.circle(image, leftmost, 10, (0, 0, 255), -1)      # red\n",
    "    cv2.circle(image, rightmost, 10, (0, 255, 0), -1)     # green\n",
    "    cv2.circle(image, topmost, 10, (255, 0, 0), -1)       # blue\n",
    "    cv2.circle(image, bottommost, 10, (255, 0, 255), -1)  # pink\n",
    "    \n",
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching Contours Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.matchShapes(contour template, contour, method, method parameter)\n",
    "# Output => match value (lower values means a closer match)\n",
    "\n",
    "# Contour Template => This is our reference contour that we’re trying to find in the new image\n",
    "# Contour => The individual contour we are checking against\n",
    "# Method => Type of contour matching (1, 2, 3)\n",
    "# Method Parameter => leave alone as 0.0 (not fully utilized in python OpenCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13081816783853514\n",
      "0.1590200533978871\n",
      "0.1498791568252558\n",
      "0.07094034474475601\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the shape template or reference image\n",
    "template = cv2.imread('images/4star.jpg',0)\n",
    "cv2.imshow('Template', template)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Load the target image with the shapes we're trying to match\n",
    "target = cv2.imread('images/shapestomatch.jpg')\n",
    "target_gray = cv2.cvtColor(target,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold both images first before using cv2.findContours\n",
    "ret, thresh1 = cv2.threshold(template, 127, 255, 0)\n",
    "ret, thresh2 = cv2.threshold(target_gray, 127, 255, 0)\n",
    "\n",
    "# Find contours in template\n",
    "contours, hierarchy = cv2.findContours(thresh1, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# We need to sort the contours by area so that we can remove the largest contour which is the image outline\n",
    "sorted_contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "# We extract the second largest contour which will be our template contour\n",
    "template_contour = contours[1]\n",
    "\n",
    "# Extract contours from second target image\n",
    "contours, hierarchy = cv2.findContours(thresh2, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for c in contours:\n",
    "    # Iterate through each contour in the target image & use cv2.matchShapes to compare contour shapes\n",
    "    match = cv2.matchShapes(template_contour, c, 3, 0.0)\n",
    "    print(match)\n",
    "    # If the match value is less than 0.15 we\n",
    "    if match < 0.15:\n",
    "        closest_contour = c\n",
    "    else:\n",
    "        closest_contour = [] \n",
    "                \n",
    "cv2.drawContours(target, [closest_contour], -1, (0,255,0), 3)\n",
    "cv2.imshow('Output', target)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load and then gray scale image\n",
    "image = cv2.imread('images/someshapes.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Identifying Shapes',image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Thresholding\n",
    "ret, thresh = cv2.threshold(gray, 127, 255, 1)\n",
    "\n",
    "# Extract Contours\n",
    "contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "for cnt in contours:\n",
    "    \n",
    "    # Get approximate polygons\n",
    "    approx = cv2.approxPolyDP(cnt, 0.01*cv2.arcLength(cnt,True),True)\n",
    "    \n",
    "    if len(approx) == 3:\n",
    "        shape_name = \"Triangle\"\n",
    "        cv2.drawContours(image,[cnt],0,(0,255,0),-1)\n",
    "        \n",
    "        # Find contour center to place text at the center\n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10'] / M['m00'])\n",
    "        cy = int(M['m01'] / M['m00'])\n",
    "        cv2.putText(image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "    \n",
    "    elif len(approx) == 4:\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10'] / M['m00'])\n",
    "        cy = int(M['m01'] / M['m00'])\n",
    "        \n",
    "        # Check to see if 4-side polygon is square or rectangle\n",
    "        # cv2.boundingRect returns the top left and then width and \n",
    "        if abs(w-h) <= 3:\n",
    "            shape_name = \"Square\"\n",
    "            \n",
    "            # Find contour center to place text at the center\n",
    "            cv2.drawContours(image, [cnt], 0, (0, 125 ,255), -1)\n",
    "            cv2.putText(image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "        else:\n",
    "            shape_name = \"Rectangle\"\n",
    "            \n",
    "            # Find contour center to place text at the center\n",
    "            cv2.drawContours(image, [cnt], 0, (0, 0, 255), -1)\n",
    "            M = cv2.moments(cnt)\n",
    "            cx = int(M['m10'] / M['m00'])\n",
    "            cy = int(M['m01'] / M['m00'])\n",
    "            cv2.putText(image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "            \n",
    "    elif len(approx) == 10:\n",
    "        shape_name = \"Star\"\n",
    "        cv2.drawContours(image, [cnt], 0, (255, 255, 0), -1)\n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10'] / M['m00'])\n",
    "        cy = int(M['m01'] / M['m00'])\n",
    "        cv2.putText(image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "        \n",
    "    elif len(approx) >= 15:\n",
    "        shape_name = \"Circle\"\n",
    "        cv2.drawContours(image, [cnt], 0, (0, 255, 255), -1)\n",
    "        M = cv2.moments(cnt)\n",
    "        cx = int(M['m10'] / M['m00'])\n",
    "        cy = int(M['m01'] / M['m00'])\n",
    "        cv2.putText(image, shape_name, (cx-50, cy), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "\n",
    "    cv2.imshow('Identifying Shapes',image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion Detection & Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture('images/walking.avi')\n",
    "\n",
    "ret1, frame1 = cap.read()\n",
    "ret2, frame2 = cap.read()\n",
    "                       \n",
    "while cap.isOpened():\n",
    "    if(ret2):\n",
    "        frame = frame1.copy()\n",
    "        diff = cv2.absdiff(frame1, frame2)\n",
    "        gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        _, thresh = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY)\n",
    "        dilated = cv2.dilate(thresh, None, iterations=3)\n",
    "\n",
    "        contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cv2.drawContours(frame1, contours, -1, (0, 255, 0), 2)\n",
    "        cv2.imshow(\"MDT1\", frame1)\n",
    "        \n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) > 800:\n",
    "                (x, y, w, h) = cv2.boundingRect(contour)\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                cv2.imshow(\"MDT2\", frame)\n",
    "        \n",
    "        frame1 = frame2\n",
    "        ret2, frame2 = cap.read()\n",
    "                       \n",
    "    if cv2.waitKey(40)==27 or ret2==False:   # Escape Key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
