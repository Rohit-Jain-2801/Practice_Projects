{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('winequality-red.csv', sep=';')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity           float64\n",
       "volatile acidity        float64\n",
       "citric acid             float64\n",
       "residual sugar          float64\n",
       "chlorides               float64\n",
       "free sulfur dioxide     float64\n",
       "total sulfur dioxide    float64\n",
       "density                 float64\n",
       "pH                      float64\n",
       "sulphates               float64\n",
       "alcohol                 float64\n",
       "quality                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity           0\n",
       "volatile acidity        0\n",
       "citric acid             0\n",
       "residual sugar          0\n",
       "chlorides               0\n",
       "free sulfur dioxide     0\n",
       "total sulfur dioxide    0\n",
       "density                 0\n",
       "pH                      0\n",
       "sulphates               0\n",
       "alcohol                 0\n",
       "quality                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     5.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28b7911f108>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['quality'].hist(figsize=(15, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffling the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.3</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.39</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.064</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.99840</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.49</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.060</td>\n",
       "      <td>26.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.99740</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.76</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.6</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.76</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.100</td>\n",
       "      <td>6.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.00320</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.68</td>\n",
       "      <td>11.2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.1</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.078</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.33</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.068</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.99470</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.60</td>\n",
       "      <td>11.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.080</td>\n",
       "      <td>35.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.99693</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>8.6</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.110</td>\n",
       "      <td>19.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.99720</td>\n",
       "      <td>2.93</td>\n",
       "      <td>1.98</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>8.5</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.369</td>\n",
       "      <td>15.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.99634</td>\n",
       "      <td>3.01</td>\n",
       "      <td>1.10</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.114</td>\n",
       "      <td>9.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.99732</td>\n",
       "      <td>3.66</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.1</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.081</td>\n",
       "      <td>13.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.99631</td>\n",
       "      <td>3.60</td>\n",
       "      <td>0.66</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               9.3             0.410         0.39             2.2      0.064   \n",
       "1               7.0             0.490         0.49             5.6      0.060   \n",
       "2              15.6             0.685         0.76             3.7      0.100   \n",
       "3               9.1             0.765         0.04             1.6      0.078   \n",
       "4               7.4             0.350         0.33             2.4      0.068   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            7.1             0.360         0.30             1.6      0.080   \n",
       "1595            8.6             0.490         0.29             2.0      0.110   \n",
       "1596            8.5             0.440         0.50             1.9      0.369   \n",
       "1597            6.5             0.460         0.14             2.4      0.114   \n",
       "1598            6.1             0.705         0.10             2.8      0.081   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    12.0                  31.0  0.99840  3.26       0.65   \n",
       "1                    26.0                 121.0  0.99740  3.34       0.76   \n",
       "2                     6.0                  43.0  1.00320  2.95       0.68   \n",
       "3                     4.0                  14.0  0.99800  3.29       0.54   \n",
       "4                     9.0                  26.0  0.99470  3.36       0.60   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 35.0                  70.0  0.99693  3.44       0.50   \n",
       "1595                 19.0                 133.0  0.99720  2.93       1.98   \n",
       "1596                 15.0                  38.0  0.99634  3.01       1.10   \n",
       "1597                  9.0                  37.0  0.99732  3.66       0.65   \n",
       "1598                 13.0                  28.0  0.99631  3.60       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0        10.2        5  \n",
       "1        10.5        5  \n",
       "2        11.2        7  \n",
       "3         9.7        4  \n",
       "4        11.9        6  \n",
       "...       ...      ...  \n",
       "1594      9.4        5  \n",
       "1595      9.8        5  \n",
       "1596      9.4        5  \n",
       "1597      9.8        5  \n",
       "1598     10.2        5  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting dataframe into dependent & independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()\n",
    "X = sc_X.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = y/10\n",
    "# y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into training & test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_divide, y_train, y_divide = train_test_split(X, y, test_size=0.2)\n",
    "X_validate, X_test, y_validate, y_test = train_test_split(X_divide, y_divide, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=8, activation='relu', input_dim=11),\n",
    "    tf.keras.layers.Dropout(rate=0.2),   # To overcome overfitting\n",
    "    tf.keras.layers.Dense(units=4, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=4, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1, activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy', 'RootMeanSquaredError'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # custom callback\n",
    "# class myCallback(tf.keras.callbacks.Callback):\n",
    "#     def on_epoch_end(self, epoch, logs={}):\n",
    "#         if(logs.get('loss')<0.4):\n",
    "#             print(\"\\nLoss is low so cancelling training!\")\n",
    "#             self.model.stop_training = True\n",
    "            \n",
    "# early_stopping = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1279 samples, validate on 160 samples\n",
      "Epoch 1/100\n",
      "1279/1279 - 3s - loss: 29.7661 - accuracy: 0.0000e+00 - RootMeanSquaredError: 5.4558 - val_loss: 23.4383 - val_accuracy: 0.0000e+00 - val_RootMeanSquaredError: 4.8413\n",
      "Epoch 2/100\n",
      "1279/1279 - 0s - loss: 16.0926 - accuracy: 0.0000e+00 - RootMeanSquaredError: 4.0116 - val_loss: 8.1739 - val_accuracy: 0.0000e+00 - val_RootMeanSquaredError: 2.8590\n",
      "Epoch 3/100\n",
      "1279/1279 - 0s - loss: 7.3805 - accuracy: 0.0000e+00 - RootMeanSquaredError: 2.7167 - val_loss: 3.8236 - val_accuracy: 0.0000e+00 - val_RootMeanSquaredError: 1.9554\n",
      "Epoch 4/100\n",
      "1279/1279 - 0s - loss: 5.1282 - accuracy: 0.0000e+00 - RootMeanSquaredError: 2.2646 - val_loss: 2.4090 - val_accuracy: 0.0000e+00 - val_RootMeanSquaredError: 1.5521\n",
      "Epoch 5/100\n",
      "1279/1279 - 0s - loss: 3.7582 - accuracy: 0.0000e+00 - RootMeanSquaredError: 1.9386 - val_loss: 1.5891 - val_accuracy: 0.0000e+00 - val_RootMeanSquaredError: 1.2606\n",
      "Epoch 6/100\n",
      "1279/1279 - 0s - loss: 2.7750 - accuracy: 0.0000e+00 - RootMeanSquaredError: 1.6658 - val_loss: 1.2222 - val_accuracy: 0.0000e+00 - val_RootMeanSquaredError: 1.1055\n",
      "Epoch 7/100\n",
      "1279/1279 - 0s - loss: 2.3857 - accuracy: 0.0000e+00 - RootMeanSquaredError: 1.5446 - val_loss: 0.9834 - val_accuracy: 0.0000e+00 - val_RootMeanSquaredError: 0.9917\n",
      "Epoch 8/100\n",
      "1279/1279 - 0s - loss: 1.7864 - accuracy: 0.0000e+00 - RootMeanSquaredError: 1.3365 - val_loss: 0.8878 - val_accuracy: 0.0000e+00 - val_RootMeanSquaredError: 0.9422\n",
      "Epoch 9/100\n",
      "1279/1279 - 0s - loss: 1.6162 - accuracy: 0.0000e+00 - RootMeanSquaredError: 1.2713 - val_loss: 0.7680 - val_accuracy: 0.0000e+00 - val_RootMeanSquaredError: 0.8763\n",
      "Epoch 10/100\n",
      "1279/1279 - 0s - loss: 1.4426 - accuracy: 0.0000e+00 - RootMeanSquaredError: 1.2011 - val_loss: 0.6757 - val_accuracy: 0.0000e+00 - val_RootMeanSquaredError: 0.8220\n",
      "Epoch 11/100\n",
      "1279/1279 - 0s - loss: 1.3566 - accuracy: 0.0000e+00 - RootMeanSquaredError: 1.1647 - val_loss: 0.6165 - val_accuracy: 0.0000e+00 - val_RootMeanSquaredError: 0.7852\n",
      "Epoch 12/100\n",
      "1279/1279 - 0s - loss: 1.1661 - accuracy: 0.0000e+00 - RootMeanSquaredError: 1.0798 - val_loss: 0.5653 - val_accuracy: 0.0000e+00 - val_RootMeanSquaredError: 0.7519\n",
      "Epoch 13/100\n",
      "1279/1279 - 0s - loss: 0.9967 - accuracy: 0.0000e+00 - RootMeanSquaredError: 0.9984 - val_loss: 0.5386 - val_accuracy: 0.0000e+00 - val_RootMeanSquaredError: 0.7339\n",
      "Epoch 14/100\n",
      "1279/1279 - 0s - loss: 0.9002 - accuracy: 0.0000e+00 - RootMeanSquaredError: 0.9488 - val_loss: 0.4887 - val_accuracy: 0.0000e+00 - val_RootMeanSquaredError: 0.6991\n",
      "Epoch 15/100\n",
      "1279/1279 - 0s - loss: 0.8546 - accuracy: 0.0000e+00 - RootMeanSquaredError: 0.9245 - val_loss: 0.4642 - val_accuracy: 0.0000e+00 - val_RootMeanSquaredError: 0.6813\n",
      "Epoch 16/100\n",
      "1279/1279 - 0s - loss: 0.7089 - accuracy: 0.0000e+00 - RootMeanSquaredError: 0.8419 - val_loss: 0.4433 - val_accuracy: 0.0000e+00 - val_RootMeanSquaredError: 0.6658\n",
      "Epoch 17/100\n",
      "1279/1279 - 0s - loss: 0.6713 - accuracy: 0.0000e+00 - RootMeanSquaredError: 0.8193 - val_loss: 0.4264 - val_accuracy: 0.0000e+00 - val_RootMeanSquaredError: 0.6530\n",
      "Epoch 18/100\n",
      "1279/1279 - 0s - loss: 0.6504 - accuracy: 0.0000e+00 - RootMeanSquaredError: 0.8065 - val_loss: 0.4277 - val_accuracy: 0.0000e+00 - val_RootMeanSquaredError: 0.6540\n",
      "Epoch 19/100\n",
      "1279/1279 - 0s - loss: 0.6089 - accuracy: 0.0000e+00 - RootMeanSquaredError: 0.7803 - val_loss: 0.4100 - val_accuracy: 0.0000e+00 - val_RootMeanSquaredError: 0.6403\n",
      "Epoch 20/100\n",
      "1279/1279 - 0s - loss: 0.5802 - accuracy: 0.0000e+00 - RootMeanSquaredError: 0.7617 - val_loss: 0.4023 - val_accuracy: 0.0000e+00 - val_RootMeanSquaredError: 0.6342\n",
      "Epoch 21/100\n",
      "1279/1279 - 0s - loss: 0.5583 - accuracy: 0.0000e+00 - RootMeanSquaredError: 0.7472 - val_loss: 0.3964 - val_accuracy: 0.0000e+00 - val_RootMeanSquaredError: 0.6296\n",
      "Epoch 22/100\n",
      "1279/1279 - 0s - loss: 0.5389 - accuracy: 0.0000e+00 - RootMeanSquaredError: 0.7341 - val_loss: 0.3871 - val_accuracy: 0.0000e+00 - val_RootMeanSquaredError: 0.6221\n",
      "Epoch 23/100\n",
      "1279/1279 - 0s - loss: 0.5040 - accuracy: 0.0000e+00 - RootMeanSquaredError: 0.7099 - val_loss: 0.3958 - val_accuracy: 0.0000e+00 - val_RootMeanSquaredError: 0.6291\n",
      "Epoch 24/100\n",
      "1279/1279 - 0s - loss: 0.4975 - accuracy: 0.0000e+00 - RootMeanSquaredError: 0.7053 - val_loss: 0.3882 - val_accuracy: 0.0000e+00 - val_RootMeanSquaredError: 0.6231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28b7b3f23c8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_validate, y_validate), callbacks=[early_stopping], epochs=100, batch_size=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.224605</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.703047</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.940955</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.417463</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.187199</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>6.199329</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>5.713751</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>5.215928</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>5.975677</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>5.181657</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Predicted  True\n",
       "0     5.224605     5\n",
       "1     5.703047     6\n",
       "2     5.940955     6\n",
       "3     5.417463     5\n",
       "4     5.187199     5\n",
       "..         ...   ...\n",
       "155   6.199329     4\n",
       "156   5.713751     6\n",
       "157   5.215928     5\n",
       "158   5.975677     6\n",
       "159   5.181657     6\n",
       "\n",
       "[160 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pd.DataFrame(y_pred, columns=['Predicted']), pd.DataFrame(y_test, columns=['True'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score: 0.299913187704572\n",
      "Root_Mean_Squared_Error:  0.6744976200310918\n"
     ]
    }
   ],
   "source": [
    "print('R2_Score:', metrics.r2_score(y_test, y_pred))  # Best possible score is 1.0\n",
    "print('Root_Mean_Squared_Error: ', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))  # Should be as low as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating using K-Fold Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=8, activation='relu', input_dim=11),\n",
    "        tf.keras.layers.Dense(units=4, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=4, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=1, activation='relu')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['RootMeanSquaredError'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = tf.keras.wrappers.scikit_learn.KerasRegressor(build_fn=build_model, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = cross_val_score(estimator=regressor, X=X_train, y=y_train, cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-32.57031229, -32.25781238, -32.55468732,  -0.4394861 ,\n",
       "        -0.51723033,  -0.49536342,  -0.46773865,  -0.41286973,\n",
       "       -32.22656217,  -0.34038489])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: -32.57031229138374\n",
      "Max: -0.34038489446865294\n",
      "Mean: -13.228244729125763\n",
      "Standard Deviation: 15.655980503097968\n"
     ]
    }
   ],
   "source": [
    "print('Min:', min(accuracies))\n",
    "print('Max:', max(accuracies))\n",
    "print('Mean:', accuracies.mean())\n",
    "print('Standard Deviation:', accuracies.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(opt):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=8, activation='relu', input_dim=11),\n",
    "        tf.keras.layers.Dense(units=4, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=4, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=1, activation='relu')\n",
    "    ])\n",
    "    model.compile(optimizer=opt, loss='mean_squared_error', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = tf.keras.wrappers.scikit_learn.KerasRegressor(build_fn=build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'batch_size': [10, 25, 32], 'opt': ['adam', 'rmsprop'], 'epochs': [100, 200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=regressor, param_grid=parameters, scoring='r2', cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1279 samples\n",
      "Epoch 1/200\n",
      "1279/1279 [==============================] - 2s 2ms/sample - loss: 15.3710 - accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "1279/1279 [==============================] - 0s 155us/sample - loss: 4.2200 - accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "1279/1279 [==============================] - 0s 142us/sample - loss: 2.4461 - accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "1279/1279 [==============================] - 0s 242us/sample - loss: 1.8866 - accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "1279/1279 [==============================] - 0s 253us/sample - loss: 1.5572 - accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "1279/1279 [==============================] - 0s 234us/sample - loss: 1.3248 - accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "1279/1279 [==============================] - 0s 237us/sample - loss: 1.1740 - accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "1279/1279 [==============================] - 0s 245us/sample - loss: 1.0378 - accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "1279/1279 [==============================] - 0s 218us/sample - loss: 0.9389 - accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "1279/1279 [==============================] - 0s 240us/sample - loss: 0.8527 - accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "1279/1279 [==============================] - 0s 234us/sample - loss: 0.7814 - accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "1279/1279 [==============================] - 0s 223us/sample - loss: 0.7227 - accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "1279/1279 [==============================] - 0s 240us/sample - loss: 0.6746 - accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "1279/1279 [==============================] - 0s 231us/sample - loss: 0.6321 - accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "1279/1279 [==============================] - 0s 232us/sample - loss: 0.6013 - accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "1279/1279 [==============================] - 0s 162us/sample - loss: 0.5730 - accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "1279/1279 [==============================] - 0s 141us/sample - loss: 0.5505 - accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "1279/1279 [==============================] - 0s 151us/sample - loss: 0.5327 - accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "1279/1279 [==============================] - 0s 136us/sample - loss: 0.5170 - accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "1279/1279 [==============================] - 0s 157us/sample - loss: 0.5048 - accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "1279/1279 [==============================] - 0s 138us/sample - loss: 0.4936 - accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "1279/1279 [==============================] - 0s 128us/sample - loss: 0.4814 - accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "1279/1279 [==============================] - 0s 149us/sample - loss: 0.4714 - accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "1279/1279 [==============================] - 0s 153us/sample - loss: 0.4632 - accuracy: 0.0000e+00\n",
      "Epoch 25/200\n",
      "1279/1279 [==============================] - 0s 147us/sample - loss: 0.4589 - accuracy: 0.0000e+00\n",
      "Epoch 26/200\n",
      "1279/1279 [==============================] - 0s 188us/sample - loss: 0.4541 - accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "1279/1279 [==============================] - 0s 195us/sample - loss: 0.4518 - accuracy: 0.0000e+00\n",
      "Epoch 28/200\n",
      "1279/1279 [==============================] - 0s 205us/sample - loss: 0.4462 - accuracy: 0.0000e+00\n",
      "Epoch 29/200\n",
      "1279/1279 [==============================] - 0s 208us/sample - loss: 0.4369 - accuracy: 0.0000e+00\n",
      "Epoch 30/200\n",
      "1279/1279 [==============================] - 0s 242us/sample - loss: 0.4389 - accuracy: 0.0000e+00\n",
      "Epoch 31/200\n",
      "1279/1279 [==============================] - 0s 196us/sample - loss: 0.4368 - accuracy: 0.0000e+00\n",
      "Epoch 32/200\n",
      "1279/1279 [==============================] - 0s 143us/sample - loss: 0.4332 - accuracy: 0.0000e+00\n",
      "Epoch 33/200\n",
      "1279/1279 [==============================] - 0s 139us/sample - loss: 0.4339 - accuracy: 0.0000e+00\n",
      "Epoch 34/200\n",
      "1279/1279 [==============================] - 0s 159us/sample - loss: 0.4297 - accuracy: 0.0000e+00\n",
      "Epoch 35/200\n",
      "1279/1279 [==============================] - 0s 143us/sample - loss: 0.4306 - accuracy: 0.0000e+00\n",
      "Epoch 36/200\n",
      "1279/1279 [==============================] - 0s 152us/sample - loss: 0.4270 - accuracy: 0.0000e+00\n",
      "Epoch 37/200\n",
      "1279/1279 [==============================] - 0s 152us/sample - loss: 0.4282 - accuracy: 0.0000e+00\n",
      "Epoch 38/200\n",
      "1279/1279 [==============================] - 0s 197us/sample - loss: 0.4230 - accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "1279/1279 [==============================] - 0s 217us/sample - loss: 0.4269 - accuracy: 0.0000e+00\n",
      "Epoch 40/200\n",
      "1279/1279 [==============================] - 0s 253us/sample - loss: 0.4283 - accuracy: 0.0000e+00\n",
      "Epoch 41/200\n",
      "1279/1279 [==============================] - 0s 240us/sample - loss: 0.4195 - accuracy: 0.0000e+00\n",
      "Epoch 42/200\n",
      "1279/1279 [==============================] - 0s 229us/sample - loss: 0.4284 - accuracy: 0.0000e+00\n",
      "Epoch 43/200\n",
      "1279/1279 [==============================] - 0s 242us/sample - loss: 0.4201 - accuracy: 0.0000e+00\n",
      "Epoch 44/200\n",
      "1279/1279 [==============================] - 0s 229us/sample - loss: 0.4190 - accuracy: 0.0000e+00\n",
      "Epoch 45/200\n",
      "1279/1279 [==============================] - 0s 147us/sample - loss: 0.4197 - accuracy: 0.0000e+00\n",
      "Epoch 46/200\n",
      "1279/1279 [==============================] - 0s 147us/sample - loss: 0.4160 - accuracy: 0.0000e+00\n",
      "Epoch 47/200\n",
      "1279/1279 [==============================] - 0s 122us/sample - loss: 0.4174 - accuracy: 0.0000e+00\n",
      "Epoch 48/200\n",
      "1279/1279 [==============================] - 0s 122us/sample - loss: 0.4155 - accuracy: 0.0000e+00\n",
      "Epoch 49/200\n",
      "1279/1279 [==============================] - 0s 159us/sample - loss: 0.4152 - accuracy: 0.0000e+00\n",
      "Epoch 50/200\n",
      "1279/1279 [==============================] - 0s 254us/sample - loss: 0.4161 - accuracy: 0.0000e+00\n",
      "Epoch 51/200\n",
      "1279/1279 [==============================] - 0s 162us/sample - loss: 0.4153 - accuracy: 0.0000e+00\n",
      "Epoch 52/200\n",
      "1279/1279 [==============================] - 0s 148us/sample - loss: 0.4107 - accuracy: 0.0000e+00\n",
      "Epoch 53/200\n",
      "1279/1279 [==============================] - 0s 148us/sample - loss: 0.4126 - accuracy: 0.0000e+00\n",
      "Epoch 54/200\n",
      "1279/1279 [==============================] - 0s 148us/sample - loss: 0.4097 - accuracy: 0.0000e+00\n",
      "Epoch 55/200\n",
      "1279/1279 [==============================] - 0s 136us/sample - loss: 0.4153 - accuracy: 0.0000e+00\n",
      "Epoch 56/200\n",
      "1279/1279 [==============================] - 0s 134us/sample - loss: 0.4119 - accuracy: 0.0000e+00\n",
      "Epoch 57/200\n",
      "1279/1279 [==============================] - 0s 122us/sample - loss: 0.4164 - accuracy: 0.0000e+00\n",
      "Epoch 58/200\n",
      "1279/1279 [==============================] - 0s 122us/sample - loss: 0.4106 - accuracy: 0.0000e+00\n",
      "Epoch 59/200\n",
      "1279/1279 [==============================] - 0s 138us/sample - loss: 0.4131 - accuracy: 0.0000e+00\n",
      "Epoch 60/200\n",
      "1279/1279 [==============================] - 0s 191us/sample - loss: 0.4076 - accuracy: 0.0000e+00\n",
      "Epoch 61/200\n",
      "1279/1279 [==============================] - 0s 208us/sample - loss: 0.4117 - accuracy: 0.0000e+00\n",
      "Epoch 62/200\n",
      "1279/1279 [==============================] - 0s 186us/sample - loss: 0.4093 - accuracy: 0.0000e+00\n",
      "Epoch 63/200\n",
      "1279/1279 [==============================] - 0s 176us/sample - loss: 0.4042 - accuracy: 0.0000e+00\n",
      "Epoch 64/200\n",
      "1279/1279 [==============================] - 0s 160us/sample - loss: 0.4070 - accuracy: 0.0000e+00\n",
      "Epoch 65/200\n",
      "1279/1279 [==============================] - 0s 148us/sample - loss: 0.4080 - accuracy: 0.0000e+00\n",
      "Epoch 66/200\n",
      "1279/1279 [==============================] - 0s 146us/sample - loss: 0.4077 - accuracy: 0.0000e+00\n",
      "Epoch 67/200\n",
      "1279/1279 [==============================] - 0s 138us/sample - loss: 0.4072 - accuracy: 0.0000e+00\n",
      "Epoch 68/200\n",
      "1279/1279 [==============================] - 0s 217us/sample - loss: 0.4008 - accuracy: 0.0000e+00\n",
      "Epoch 69/200\n",
      "1279/1279 [==============================] - 0s 225us/sample - loss: 0.4043 - accuracy: 0.0000e+00\n",
      "Epoch 70/200\n",
      "1279/1279 [==============================] - 0s 280us/sample - loss: 0.4061 - accuracy: 0.0000e+00\n",
      "Epoch 71/200\n",
      "1279/1279 [==============================] - 0s 243us/sample - loss: 0.4021 - accuracy: 0.0000e+00\n",
      "Epoch 72/200\n",
      "1279/1279 [==============================] - 0s 208us/sample - loss: 0.4069 - accuracy: 0.0000e+00\n",
      "Epoch 73/200\n",
      "1279/1279 [==============================] - 0s 134us/sample - loss: 0.4082 - accuracy: 0.0000e+00\n",
      "Epoch 74/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279/1279 [==============================] - 0s 134us/sample - loss: 0.4030 - accuracy: 0.0000e+00\n",
      "Epoch 75/200\n",
      "1279/1279 [==============================] - 0s 122us/sample - loss: 0.4026 - accuracy: 0.0000e+00\n",
      "Epoch 76/200\n",
      "1279/1279 [==============================] - 0s 134us/sample - loss: 0.3995 - accuracy: 0.0000e+00\n",
      "Epoch 77/200\n",
      "1279/1279 [==============================] - 0s 146us/sample - loss: 0.4020 - accuracy: 0.0000e+00\n",
      "Epoch 78/200\n",
      "1279/1279 [==============================] - 0s 273us/sample - loss: 0.4025 - accuracy: 0.0000e+00\n",
      "Epoch 79/200\n",
      "1279/1279 [==============================] - 0s 203us/sample - loss: 0.3978 - accuracy: 0.0000e+00\n",
      "Epoch 80/200\n",
      "1279/1279 [==============================] - 0s 221us/sample - loss: 0.4009 - accuracy: 0.0000e+00\n",
      "Epoch 81/200\n",
      "1279/1279 [==============================] - 0s 239us/sample - loss: 0.3994 - accuracy: 0.0000e+00\n",
      "Epoch 82/200\n",
      "1279/1279 [==============================] - 0s 201us/sample - loss: 0.3968 - accuracy: 0.0000e+00\n",
      "Epoch 83/200\n",
      "1279/1279 [==============================] - 0s 134us/sample - loss: 0.4002 - accuracy: 0.0000e+00\n",
      "Epoch 84/200\n",
      "1279/1279 [==============================] - 0s 122us/sample - loss: 0.3985 - accuracy: 0.0000e+00\n",
      "Epoch 85/200\n",
      "1279/1279 [==============================] - 0s 126us/sample - loss: 0.4013 - accuracy: 0.0000e+00\n",
      "Epoch 86/200\n",
      "1279/1279 [==============================] - 0s 195us/sample - loss: 0.3973 - accuracy: 0.0000e+00\n",
      "Epoch 87/200\n",
      "1279/1279 [==============================] - 0s 195us/sample - loss: 0.3963 - accuracy: 0.0000e+00\n",
      "Epoch 88/200\n",
      "1279/1279 [==============================] - 0s 263us/sample - loss: 0.3958 - accuracy: 0.0000e+00\n",
      "Epoch 89/200\n",
      "1279/1279 [==============================] - 0s 145us/sample - loss: 0.3968 - accuracy: 0.0000e+00\n",
      "Epoch 90/200\n",
      "1279/1279 [==============================] - 0s 130us/sample - loss: 0.3999 - accuracy: 0.0000e+00\n",
      "Epoch 91/200\n",
      "1279/1279 [==============================] - 0s 159us/sample - loss: 0.3971 - accuracy: 0.0000e+00\n",
      "Epoch 92/200\n",
      "1279/1279 [==============================] - 0s 122us/sample - loss: 0.3971 - accuracy: 0.0000e+00\n",
      "Epoch 93/200\n",
      "1279/1279 [==============================] - 0s 122us/sample - loss: 0.3957 - accuracy: 0.0000e+00\n",
      "Epoch 94/200\n",
      "1279/1279 [==============================] - 0s 134us/sample - loss: 0.3958 - accuracy: 0.0000e+00\n",
      "Epoch 95/200\n",
      "1279/1279 [==============================] - 0s 209us/sample - loss: 0.3969 - accuracy: 0.0000e+00\n",
      "Epoch 96/200\n",
      "1279/1279 [==============================] - 0s 146us/sample - loss: 0.3973 - accuracy: 0.0000e+00\n",
      "Epoch 97/200\n",
      "1279/1279 [==============================] - 0s 143us/sample - loss: 0.3982 - accuracy: 0.0000e+00\n",
      "Epoch 98/200\n",
      "1279/1279 [==============================] - 0s 183us/sample - loss: 0.4033 - accuracy: 0.0000e+00\n",
      "Epoch 99/200\n",
      "1279/1279 [==============================] - 0s 209us/sample - loss: 0.3970 - accuracy: 0.0000e+00\n",
      "Epoch 100/200\n",
      "1279/1279 [==============================] - 0s 243us/sample - loss: 0.3926 - accuracy: 0.0000e+00\n",
      "Epoch 101/200\n",
      "1279/1279 [==============================] - 0s 219us/sample - loss: 0.3951 - accuracy: 0.0000e+00\n",
      "Epoch 102/200\n",
      "1279/1279 [==============================] - 0s 209us/sample - loss: 0.3986 - accuracy: 0.0000e+00\n",
      "Epoch 103/200\n",
      "1279/1279 [==============================] - 0s 217us/sample - loss: 0.3945 - accuracy: 0.0000e+00\n",
      "Epoch 104/200\n",
      "1279/1279 [==============================] - 0s 239us/sample - loss: 0.3958 - accuracy: 0.0000e+00\n",
      "Epoch 105/200\n",
      "1279/1279 [==============================] - 0s 217us/sample - loss: 0.3973 - accuracy: 0.0000e+00\n",
      "Epoch 106/200\n",
      "1279/1279 [==============================] - 0s 202us/sample - loss: 0.3931 - accuracy: 0.0000e+00\n",
      "Epoch 107/200\n",
      "1279/1279 [==============================] - 0s 225us/sample - loss: 0.3914 - accuracy: 0.0000e+00\n",
      "Epoch 108/200\n",
      "1279/1279 [==============================] - 0s 231us/sample - loss: 0.3989 - accuracy: 0.0000e+00\n",
      "Epoch 109/200\n",
      "1279/1279 [==============================] - 0s 234us/sample - loss: 0.3945 - accuracy: 0.0000e+00\n",
      "Epoch 110/200\n",
      "1279/1279 [==============================] - 0s 220us/sample - loss: 0.3933 - accuracy: 0.0000e+00\n",
      "Epoch 111/200\n",
      "1279/1279 [==============================] - 0s 270us/sample - loss: 0.3965 - accuracy: 0.0000e+00\n",
      "Epoch 112/200\n",
      "1279/1279 [==============================] - 0s 206us/sample - loss: 0.3944 - accuracy: 0.0000e+00\n",
      "Epoch 113/200\n",
      "1279/1279 [==============================] - 0s 208us/sample - loss: 0.3918 - accuracy: 0.0000e+00\n",
      "Epoch 114/200\n",
      "1279/1279 [==============================] - 0s 159us/sample - loss: 0.3938 - accuracy: 0.0000e+00\n",
      "Epoch 115/200\n",
      "1279/1279 [==============================] - 0s 134us/sample - loss: 0.3928 - accuracy: 0.0000e+00\n",
      "Epoch 116/200\n",
      "1279/1279 [==============================] - 0s 134us/sample - loss: 0.3953 - accuracy: 0.0000e+00\n",
      "Epoch 117/200\n",
      "1279/1279 [==============================] - 0s 122us/sample - loss: 0.3921 - accuracy: 0.0000e+00\n",
      "Epoch 118/200\n",
      "1279/1279 [==============================] - 0s 122us/sample - loss: 0.3931 - accuracy: 0.0000e+00\n",
      "Epoch 119/200\n",
      "1279/1279 [==============================] - 0s 199us/sample - loss: 0.3931 - accuracy: 0.0000e+00\n",
      "Epoch 120/200\n",
      "1279/1279 [==============================] - 0s 157us/sample - loss: 0.3927 - accuracy: 0.0000e+00\n",
      "Epoch 121/200\n",
      "1279/1279 [==============================] - 0s 141us/sample - loss: 0.3907 - accuracy: 0.0000e+00\n",
      "Epoch 122/200\n",
      "1279/1279 [==============================] - 0s 151us/sample - loss: 0.3916 - accuracy: 0.0000e+00\n",
      "Epoch 123/200\n",
      "1279/1279 [==============================] - 0s 131us/sample - loss: 0.3866 - accuracy: 0.0000e+00\n",
      "Epoch 124/200\n",
      "1279/1279 [==============================] - 0s 146us/sample - loss: 0.3919 - accuracy: 0.0000e+00\n",
      "Epoch 125/200\n",
      "1279/1279 [==============================] - 0s 145us/sample - loss: 0.3935 - accuracy: 0.0000e+00\n",
      "Epoch 126/200\n",
      "1279/1279 [==============================] - 0s 142us/sample - loss: 0.3953 - accuracy: 0.0000e+00\n",
      "Epoch 127/200\n",
      "1279/1279 [==============================] - 0s 130us/sample - loss: 0.3921 - accuracy: 0.0000e+00\n",
      "Epoch 128/200\n",
      "1279/1279 [==============================] - 0s 134us/sample - loss: 0.3908 - accuracy: 0.0000e+00\n",
      "Epoch 129/200\n",
      "1279/1279 [==============================] - 0s 122us/sample - loss: 0.3933 - accuracy: 0.0000e+00\n",
      "Epoch 130/200\n",
      "1279/1279 [==============================] - 0s 134us/sample - loss: 0.3938 - accuracy: 0.0000e+00\n",
      "Epoch 131/200\n",
      "1279/1279 [==============================] - 0s 122us/sample - loss: 0.3926 - accuracy: 0.0000e+00\n",
      "Epoch 132/200\n",
      "1279/1279 [==============================] - 0s 162us/sample - loss: 0.3917 - accuracy: 0.0000e+00\n",
      "Epoch 133/200\n",
      "1279/1279 [==============================] - 0s 143us/sample - loss: 0.3909 - accuracy: 0.0000e+00\n",
      "Epoch 134/200\n",
      "1279/1279 [==============================] - 0s 147us/sample - loss: 0.3916 - accuracy: 0.0000e+00\n",
      "Epoch 135/200\n",
      "1279/1279 [==============================] - 0s 146us/sample - loss: 0.3905 - accuracy: 0.0000e+00\n",
      "Epoch 136/200\n",
      "1279/1279 [==============================] - 0s 140us/sample - loss: 0.3926 - accuracy: 0.0000e+00\n",
      "Epoch 137/200\n",
      "1279/1279 [==============================] - 0s 148us/sample - loss: 0.3927 - accuracy: 0.0000e+00\n",
      "Epoch 138/200\n",
      "1279/1279 [==============================] - 0s 155us/sample - loss: 0.3935 - accuracy: 0.0000e+00\n",
      "Epoch 139/200\n",
      "1279/1279 [==============================] - 0s 212us/sample - loss: 0.3897 - accuracy: 0.0000e+00\n",
      "Epoch 140/200\n",
      "1279/1279 [==============================] - 0s 247us/sample - loss: 0.3917 - accuracy: 0.0000e+00\n",
      "Epoch 141/200\n",
      "1279/1279 [==============================] - 0s 242us/sample - loss: 0.3908 - accuracy: 0.0000e+00\n",
      "Epoch 142/200\n",
      "1279/1279 [==============================] - 0s 243us/sample - loss: 0.3922 - accuracy: 0.0000e+00\n",
      "Epoch 143/200\n",
      "1279/1279 [==============================] - 0s 203us/sample - loss: 0.3896 - accuracy: 0.0000e+00\n",
      "Epoch 144/200\n",
      "1279/1279 [==============================] - 0s 147us/sample - loss: 0.3874 - accuracy: 0.0000e+00\n",
      "Epoch 145/200\n",
      "1279/1279 [==============================] - 0s 122us/sample - loss: 0.3894 - accuracy: 0.0000e+00\n",
      "Epoch 146/200\n",
      "1279/1279 [==============================] - 0s 134us/sample - loss: 0.3881 - accuracy: 0.0000e+00\n",
      "Epoch 147/200\n",
      "1279/1279 [==============================] - 0s 122us/sample - loss: 0.3897 - accuracy: 0.0000e+00\n",
      "Epoch 148/200\n",
      "1279/1279 [==============================] - 0s 122us/sample - loss: 0.3892 - accuracy: 0.0000e+00\n",
      "Epoch 149/200\n",
      "1279/1279 [==============================] - 0s 170us/sample - loss: 0.3901 - accuracy: 0.0000e+00\n",
      "Epoch 150/200\n",
      "1279/1279 [==============================] - 0s 220us/sample - loss: 0.3935 - accuracy: 0.0000e+00\n",
      "Epoch 151/200\n",
      "1279/1279 [==============================] - 0s 186us/sample - loss: 0.3878 - accuracy: 0.0000e+00\n",
      "Epoch 152/200\n",
      "1279/1279 [==============================] - 0s 144us/sample - loss: 0.3897 - accuracy: 0.0000e+00\n",
      "Epoch 153/200\n",
      "1279/1279 [==============================] - 0s 149us/sample - loss: 0.3915 - accuracy: 0.0000e+00\n",
      "Epoch 154/200\n",
      "1279/1279 [==============================] - 0s 147us/sample - loss: 0.3885 - accuracy: 0.0000e+00\n",
      "Epoch 155/200\n",
      "1279/1279 [==============================] - 0s 133us/sample - loss: 0.3915 - accuracy: 0.0000e+00\n",
      "Epoch 156/200\n",
      "1279/1279 [==============================] - 0s 146us/sample - loss: 0.3872 - accuracy: 0.0000e+00\n",
      "Epoch 157/200\n",
      "1279/1279 [==============================] - 0s 223us/sample - loss: 0.3906 - accuracy: 0.0000e+00\n",
      "Epoch 158/200\n",
      "1279/1279 [==============================] - 0s 215us/sample - loss: 0.3932 - accuracy: 0.0000e+00\n",
      "Epoch 159/200\n",
      "1279/1279 [==============================] - 0s 255us/sample - loss: 0.3918 - accuracy: 0.0000e+00\n",
      "Epoch 160/200\n",
      "1279/1279 [==============================] - 0s 211us/sample - loss: 0.3886 - accuracy: 0.0000e+00\n",
      "Epoch 161/200\n",
      "1279/1279 [==============================] - 0s 218us/sample - loss: 0.3877 - accuracy: 0.0000e+00\n",
      "Epoch 162/200\n",
      "1279/1279 [==============================] - 0s 247us/sample - loss: 0.3874 - accuracy: 0.0000e+00\n",
      "Epoch 163/200\n",
      "1279/1279 [==============================] - 0s 225us/sample - loss: 0.3869 - accuracy: 0.0000e+00\n",
      "Epoch 164/200\n",
      "1279/1279 [==============================] - 0s 210us/sample - loss: 0.3886 - accuracy: 0.0000e+00\n",
      "Epoch 165/200\n",
      "1279/1279 [==============================] - 0s 223us/sample - loss: 0.3953 - accuracy: 0.0000e+00\n",
      "Epoch 166/200\n",
      "1279/1279 [==============================] - 0s 234us/sample - loss: 0.3929 - accuracy: 0.0000e+00\n",
      "Epoch 167/200\n",
      "1279/1279 [==============================] - 0s 227us/sample - loss: 0.3905 - accuracy: 0.0000e+00\n",
      "Epoch 168/200\n",
      "1279/1279 [==============================] - 0s 205us/sample - loss: 0.3902 - accuracy: 0.0000e+00\n",
      "Epoch 169/200\n",
      "1279/1279 [==============================] - 0s 231us/sample - loss: 0.3887 - accuracy: 0.0000e+00\n",
      "Epoch 170/200\n",
      "1279/1279 [==============================] - 0s 226us/sample - loss: 0.3852 - accuracy: 0.0000e+00\n",
      "Epoch 171/200\n",
      "1279/1279 [==============================] - 0s 227us/sample - loss: 0.3863 - accuracy: 0.0000e+00\n",
      "Epoch 172/200\n",
      "1279/1279 [==============================] - 0s 234us/sample - loss: 0.3902 - accuracy: 0.0000e+00\n",
      "Epoch 173/200\n",
      "1279/1279 [==============================] - 0s 236us/sample - loss: 0.3867 - accuracy: 0.0000e+00\n",
      "Epoch 174/200\n",
      "1279/1279 [==============================] - 0s 225us/sample - loss: 0.3873 - accuracy: 0.0000e+00\n",
      "Epoch 175/200\n",
      "1279/1279 [==============================] - 0s 212us/sample - loss: 0.3904 - accuracy: 0.0000e+00\n",
      "Epoch 176/200\n",
      "1279/1279 [==============================] - 0s 253us/sample - loss: 0.3884 - accuracy: 0.0000e+00\n",
      "Epoch 177/200\n",
      "1279/1279 [==============================] - 0s 231us/sample - loss: 0.3884 - accuracy: 0.0000e+00\n",
      "Epoch 178/200\n",
      "1279/1279 [==============================] - 0s 247us/sample - loss: 0.3887 - accuracy: 0.0000e+00\n",
      "Epoch 179/200\n",
      "1279/1279 [==============================] - 0s 241us/sample - loss: 0.3876 - accuracy: 0.0000e+00\n",
      "Epoch 180/200\n",
      "1279/1279 [==============================] - 0s 240us/sample - loss: 0.3873 - accuracy: 0.0000e+00\n",
      "Epoch 181/200\n",
      "1279/1279 [==============================] - 0s 252us/sample - loss: 0.3895 - accuracy: 0.0000e+00\n",
      "Epoch 182/200\n",
      "1279/1279 [==============================] - 0s 201us/sample - loss: 0.3916 - accuracy: 0.0000e+00\n",
      "Epoch 183/200\n",
      "1279/1279 [==============================] - 0s 233us/sample - loss: 0.3855 - accuracy: 0.0000e+00\n",
      "Epoch 184/200\n",
      "1279/1279 [==============================] - 0s 234us/sample - loss: 0.3848 - accuracy: 0.0000e+00\n",
      "Epoch 185/200\n",
      "1279/1279 [==============================] - 0s 238us/sample - loss: 0.3864 - accuracy: 0.0000e+00\n",
      "Epoch 186/200\n",
      "1279/1279 [==============================] - 0s 226us/sample - loss: 0.3880 - accuracy: 0.0000e+00\n",
      "Epoch 187/200\n",
      "1279/1279 [==============================] - 0s 210us/sample - loss: 0.3886 - accuracy: 0.0000e+00\n",
      "Epoch 188/200\n",
      "1279/1279 [==============================] - 0s 241us/sample - loss: 0.3851 - accuracy: 0.0000e+00\n",
      "Epoch 189/200\n",
      "1279/1279 [==============================] - 0s 238us/sample - loss: 0.3898 - accuracy: 0.0000e+00\n",
      "Epoch 190/200\n",
      "1279/1279 [==============================] - 0s 208us/sample - loss: 0.3857 - accuracy: 0.0000e+00\n",
      "Epoch 191/200\n",
      "1279/1279 [==============================] - 0s 183us/sample - loss: 0.3871 - accuracy: 0.0000e+00\n",
      "Epoch 192/200\n",
      "1279/1279 [==============================] - 0s 134us/sample - loss: 0.3851 - accuracy: 0.0000e+00\n",
      "Epoch 193/200\n",
      "1279/1279 [==============================] - 0s 170us/sample - loss: 0.3868 - accuracy: 0.0000e+00\n",
      "Epoch 194/200\n",
      "1279/1279 [==============================] - 0s 195us/sample - loss: 0.3892 - accuracy: 0.0000e+00\n",
      "Epoch 195/200\n",
      "1279/1279 [==============================] - 0s 235us/sample - loss: 0.3885 - accuracy: 0.0000e+00\n",
      "Epoch 196/200\n",
      "1279/1279 [==============================] - 0s 197us/sample - loss: 0.3897 - accuracy: 0.0000e+00\n",
      "Epoch 197/200\n",
      "1279/1279 [==============================] - 0s 144us/sample - loss: 0.3852 - accuracy: 0.0000e+00\n",
      "Epoch 198/200\n",
      "1279/1279 [==============================] - 0s 160us/sample - loss: 0.3883 - accuracy: 0.0000e+00\n",
      "Epoch 199/200\n",
      "1279/1279 [==============================] - 0s 211us/sample - loss: 0.3888 - accuracy: 0.0000e+00\n",
      "Epoch 200/200\n",
      "1279/1279 [==============================] - 0s 224us/sample - loss: 0.3866 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "grid_search = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'batch_size': 10, 'epochs': 200, 'opt': 'adam'}\n",
      "Best Accuracy: 0.2929942862635161\n"
     ]
    }
   ],
   "source": [
    "print('Best Parameters:', grid_search.best_params_)\n",
    "print('Best Accuracy:', grid_search.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
